from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException
import time
from datetime import datetime, timedelta
import logging
import sys
import random
import requests
from bs4 import BeautifulSoup
import re

# é…ç½® logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger(__name__)

# å…¨å±€è®Šé‡ä¾†è·Ÿè¹¤ä¸Šæ¬¡è«‹æ±‚æ™‚é–“å’Œçµæœ
last_request_time = None
last_results = None
CACHE_DURATION = 300  # 5åˆ†é˜ç·©å­˜

def create_driver():
    """å»ºç«‹ Chrome WebDriver"""
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option('useAutomationExtension', False)
    
    # æ·»åŠ  User-Agent é¿å…è¢«è­˜åˆ¥ç‚ºæ©Ÿå™¨äºº
    chrome_options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")
    
    try:
        driver = webdriver.Chrome(options=chrome_options)
        # éš±è— webdriver ç‰¹å¾µ
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        logger.info("âœ… WebDriver å‰µå»ºæˆåŠŸ")
        return driver
    except Exception as e:
        logger.error(f"âŒ å»ºç«‹ WebDriver å¤±æ•—: {e}")
        return None

def scrape_with_requests():
    """ä½¿ç”¨ requests å˜—è©¦çˆ¬å–è³‡æ–™"""
    logger.info("ğŸ”„ å˜—è©¦ä½¿ç”¨ requests çˆ¬å–è³‡æ–™...")
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Accept-Encoding': 'gzip, deflate',
        'DNT': '1',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
    }
    
    try:
        # å˜—è©¦è¨ªå• OddsPortal ä¸»é 
        session = requests.Session()
        session.headers.update(headers)
        
        response = session.get("https://www.oddsportal.com/", timeout=10)
        if response.status_code != 200:
            logger.warning(f"âš ï¸ ä¸»é è¨ªå•å¤±æ•—: {response.status_code}")
            return []
        
        # å˜—è©¦è¨ªå•å¥—åˆ©é é¢
        response = session.get("https://www.oddsportal.com/sure-bets/", timeout=10)
        if response.status_code != 200:
            logger.warning(f"âš ï¸ å¥—åˆ©é é¢è¨ªå•å¤±æ•—: {response.status_code}")
            return []
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # æª¢æŸ¥æ˜¯å¦æœ‰åçˆ¬èŸ²ä¿è­·
        page_content = response.text.lower()
        if any(keyword in page_content for keyword in ['cloudflare', 'ddos', 'bot detection', 'access denied', 'blocked']):
            logger.warning("âš ï¸ æª¢æ¸¬åˆ°åçˆ¬èŸ²ä¿è­· (requests)")
            return []
        
        # å˜—è©¦è§£æå¥—åˆ©è³‡æ–™
        return parse_surebet_data(soup)
            
    except requests.RequestException as e:
        logger.error(f"âŒ requests çˆ¬å–å¤±æ•—: {e}")
        return []

def parse_surebet_data(soup):
    """è§£æå¥—åˆ©è³‡æ–™"""
    bets = []
    
    try:
        # å˜—è©¦æ‰¾åˆ°å¥—åˆ©è³‡æ–™è¡¨æ ¼æˆ–å®¹å™¨
        # é€™è£¡éœ€è¦æ ¹æ“šå¯¦éš›ç¶²ç«™çµæ§‹ä¾†èª¿æ•´é¸æ“‡å™¨
        surebet_containers = soup.find_all(['div', 'table', 'tr'], class_=re.compile(r'sure|bet|arbitrage', re.I))
        
        if not surebet_containers:
            logger.info("âŒ æœªæ‰¾åˆ°å¥—åˆ©è³‡æ–™å®¹å™¨")
            return []
        
        for container in surebet_containers:
            try:
                # å˜—è©¦æå–æ¯”è³½è³‡è¨Š
                match_info = extract_match_info(container)
                if match_info:
                    bets.append(match_info)
            except Exception as e:
                logger.debug(f"è§£æå®¹å™¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                continue
        
        logger.info(f"âœ… æˆåŠŸè§£æ {len(bets)} ç­†å¥—åˆ©è³‡æ–™")
        return bets
        
    except Exception as e:
        logger.error(f"âŒ è§£æå¥—åˆ©è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return []

def extract_match_info(container):
    """å¾å®¹å™¨ä¸­æå–æ¯”è³½è³‡è¨Š"""
    try:
        # é€™è£¡éœ€è¦æ ¹æ“šå¯¦éš›çš„HTMLçµæ§‹ä¾†å¯¦ç¾
        # ç›®å‰è¿”å› None è¡¨ç¤ºç„¡æ³•æå–
        return None
    except Exception as e:
        logger.debug(f"æå–æ¯”è³½è³‡è¨Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

def scrape_oddsportal_surebets():
    """
    çˆ¬å– OddsPortal çš„å¥—åˆ©æŠ•æ³¨è³‡æ–™ - åªè¿”å›çœŸå¯¦è³‡æ–™
    """
    global last_request_time, last_results
    
    # æª¢æŸ¥ç·©å­˜
    current_time = time.time()
    if (last_request_time and last_results is not None and 
        current_time - last_request_time < CACHE_DURATION):
        logger.info("ğŸ“¦ ä½¿ç”¨ç·©å­˜è³‡æ–™")
        return last_results
    
    # é¦–å…ˆå˜—è©¦ä½¿ç”¨ requests
    results = scrape_with_requests()
    if results:
        logger.info("âœ… requests çˆ¬å–æˆåŠŸ")
        last_request_time = current_time
        last_results = results
        return results
    
    # å¦‚æœ requests å¤±æ•—ï¼Œå˜—è©¦ Selenium
    driver = create_driver()
    if not driver:
        logger.error("âŒ ç„¡æ³•å‰µå»º WebDriver")
        # æ›´æ–°ç·©å­˜ç‚ºç©ºçµæœ
        last_request_time = current_time
        last_results = []
        return []
    
    bets = []
    
    try:
        logger.info("ğŸ” é–‹å§‹ä½¿ç”¨ Selenium çˆ¬å– OddsPortal å¥—åˆ©è³‡æ–™...")
        
        # è¨­ç½®é é¢è¼‰å…¥è¶…æ™‚
        driver.set_page_load_timeout(30)
        
        # å…ˆè¨ªå•ä¸»é å»ºç«‹ session
        logger.info("ğŸŒ è¨ªå• OddsPortal ä¸»é ...")
        driver.get("https://www.oddsportal.com")
        time.sleep(random.uniform(2, 4))
        
        # å†è¨ªå•å¥—åˆ©é é¢
        logger.info("ğŸŒ è¨ªå•å¥—åˆ©é é¢...")
        driver.get("https://www.oddsportal.com/sure-bets/")
        
        # ç­‰å¾…é é¢è¼‰å…¥
        wait = WebDriverWait(driver, 20)
        
        # æª¢æŸ¥é é¢æ˜¯å¦æ­£å¸¸è¼‰å…¥
        try:
            wait.until(EC.presence_of_element_located((By.TAG_NAME, "body")))
            logger.info("âœ… é é¢è¼‰å…¥å®Œæˆ")
        except TimeoutException:
            logger.error("âŒ é é¢è¼‰å…¥è¶…æ™‚")
            last_request_time = current_time
            last_results = []
            return []
        
        # æª¢æŸ¥æ˜¯å¦æœ‰åçˆ¬èŸ²ä¿è­·
        page_source = driver.page_source.lower()
        if any(keyword in page_source for keyword in ['cloudflare', 'ddos', 'bot detection', 'access denied', 'blocked']):
            logger.warning("âš ï¸ æª¢æ¸¬åˆ°åçˆ¬èŸ²ä¿è­· (Selenium)")
            last_request_time = current_time
            last_results = []
            return []
        
        # å˜—è©¦è§£æå¥—åˆ©è³‡æ–™
        bets = parse_selenium_data(driver)
        
        if not bets:
            logger.info("âŒ æœªæ‰¾åˆ°å¥—åˆ©è³‡æ–™")
            last_request_time = current_time
            last_results = []
            return []
        
        logger.info(f"âœ… æˆåŠŸçˆ¬å– {len(bets)} ç­†å¥—åˆ©è³‡æ–™")
        last_request_time = current_time
        last_results = bets
        return bets
        
    except WebDriverException as e:
        logger.error(f"âŒ WebDriver éŒ¯èª¤: {e}")
        last_request_time = current_time
        last_results = []
        return []
    except TimeoutException:
        logger.error("âŒ é é¢è¼‰å…¥è¶…æ™‚")
        last_request_time = current_time
        last_results = []
        return []
    except Exception as e:
        logger.error(f"âŒ çˆ¬èŸ²éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        last_request_time = current_time
        last_results = []
        return []
        
    finally:
        try:
            if driver:
                driver.quit()
                logger.info("ğŸ”š WebDriver å·²é—œé–‰")
        except Exception as e:
            logger.error(f"âŒ é—œé–‰ WebDriver æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

def parse_selenium_data(driver):
    """ä½¿ç”¨ Selenium è§£æå¥—åˆ©è³‡æ–™"""
    bets = []
    
    try:
        # å˜—è©¦æ‰¾åˆ°å¥—åˆ©è³‡æ–™è¡¨æ ¼
        # é€™è£¡éœ€è¦æ ¹æ“šå¯¦éš›çš„ç¶²ç«™çµæ§‹ä¾†èª¿æ•´é¸æ“‡å™¨
        possible_selectors = [
            "table.table-main",
            "[data-cy='table']",
            ".odds-table",
            ".surebet-table",
            "table",
            ".table"
        ]
        
        table_elements = []
        for selector in possible_selectors:
            try:
                elements = driver.find_elements(By.CSS_SELECTOR, selector)
                if elements:
                    table_elements.extend(elements)
                    logger.info(f"âœ… æ‰¾åˆ°è¡¨æ ¼å…ƒç´ : {selector}")
                    break
            except Exception as e:
                logger.debug(f"é¸æ“‡å™¨ {selector} å¤±æ•—: {e}")
                continue
        
        if not table_elements:
            logger.warning("âš ï¸ æœªæ‰¾åˆ°è³‡æ–™è¡¨æ ¼")
            return []
        
        # å˜—è©¦è§£æè¡¨æ ¼è³‡æ–™
        for table in table_elements:
            try:
                rows = table.find_elements(By.TAG_NAME, "tr")
                for row in rows:
                    match_data = extract_selenium_match_data(row)
                    if match_data:
                        bets.append(match_data)
            except Exception as e:
                logger.debug(f"è§£æè¡¨æ ¼æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                continue
        
        return bets
        
    except Exception as e:
        logger.error(f"âŒ ä½¿ç”¨ Selenium è§£æè³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return []

def extract_selenium_match_data(row_element):
    """å¾è¡¨æ ¼è¡Œä¸­æå–æ¯”è³½è³‡æ–™"""
    try:
        # é€™è£¡éœ€è¦æ ¹æ“šå¯¦éš›çš„HTMLçµæ§‹ä¾†å¯¦ç¾
        # ç›®å‰è¿”å› None è¡¨ç¤ºç„¡æ³•æå–
        return None
    except Exception as e:
        logger.debug(f"æå–æ¯”è³½è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

def clear_cache():
    """æ¸…é™¤ç·©å­˜"""
    global last_request_time, last_results
    last_request_time = None
    last_results = None
    logger.info("ğŸ§¹ ç·©å­˜å·²æ¸…é™¤")

def test_scraper():
    """æ¸¬è©¦çˆ¬èŸ²åŠŸèƒ½"""
    logger.info("ğŸ§ª é–‹å§‹æ¸¬è©¦çˆ¬èŸ²...")
    
    # æ¸…é™¤ç·©å­˜ç¢ºä¿ç²å–æ–°è³‡æ–™
    clear_cache()
    
    results = scrape_oddsportal_surebets()
    
    if results:
        logger.info(f"\nğŸ“‹ æ¸¬è©¦çµæœ: æ‰¾åˆ° {len(results)} ç­†å¥—åˆ©æ©Ÿæœƒ")
        for i, bet in enumerate(results):
            logger.info(f"\n{i+1}. {bet.get('sport', 'Unknown')} - {bet.get('league', 'Unknown')}")
            logger.info(f"   æ¯”è³½: {bet.get('home_team', 'Unknown')} vs {bet.get('away_team', 'Unknown')}")
            logger.info(f"   æ™‚é–“: {bet.get('match_time', 'Unknown')}")
            logger.info(f"   ROI: {bet.get('roi', 'Unknown')}%")
            logger.info(f"   åˆ©æ½¤: ${bet.get('profit', 'Unknown')}")
    else:
        logger.info("âŒ æ²’æœ‰æ‰¾åˆ°å¥—åˆ©æ©Ÿæœƒ")
    
    return results

if __name__ == "__main__":
    test_scraper()
